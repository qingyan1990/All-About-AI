# Papers
## NLP
[Neural Machine Translation by Jointly Learning to Align and Translate(seq2seq, attention)](https://arxiv.org/abs/1409.0473)  
[Attention is All You Need(self attention, transformer)](https://arxiv.org/abs/1706.03762)  
[word2vec Parameter Learning Explained(word2vec)](https://arxiv.org/pdf/1411.2738.pdf)  
## CV
# Tutorials
[The Illustrated Transformer(transformer, self attention)](https://jalammar.github.io/illustrated-transformer)  
# Github
## Paper implementations